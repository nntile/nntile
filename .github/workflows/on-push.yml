name: Linting and testing

# Trigger the workflow on push or pull request (only main branch).
on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

permissions:
  contents: read

jobs:
  lint:
    name: Linting with Python ${{ matrix.python-version }}
    runs-on: 'ubuntu-24.04'
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    steps:
      - uses: actions/checkout@v4
      - name: Pull all PR commits
        if: github.event.pull_request
        run: |
          # Un-shallow refs.
          git config remote.origin.fetch "+refs/heads/*:refs/remotes/origin/*"
          # Deepen topic branch; checkout topic branch.
          git fetch origin ${{ github.ref }}:${{ github.head_ref }} \
            --depth=$(( ${{ github.event.pull_request.commits }} + 1 ))
          git checkout ${{ github.event.pull_request.head.ref }}
          # Fetch main for common origin.
          git fetch origin main:main --depth=100
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          cache: 'pip'
          python-version: ${{ matrix.python-version }}
      - name: Run pre-commit on pull request
        uses: pre-commit/action@v3.0.0
        if: github.event.pull_request
        with:
          extra_args: >
            --from-ref "$(git merge-base main HEAD)"
            --to-ref "${{ github.head_ref }}"
      - name: Run pre-commit on merge
        uses: pre-commit/action@v3.0.0
        if: '!github.event.pull_request'

  # TODO(@daskol): We need rework this stage: pre-build images, build StarPU
  # in-tree, rework layout and defaults, etc.
  build:
    name: Build a CPU-only extension for Python ${{ matrix.python-version }}
    needs: 'lint'
    runs-on: 'ubuntu-24.04'
    strategy:
      matrix:
        python-version: ['3.12']
    container:
      image: ubuntu:24.04
    steps:
      - name: Cache system packages
        id: cache-apt
        uses: actions/cache@v4
        env:
          cache-name: cache-apt-packages
        with:
          path: /var/cache/apt
          key: ${{ runner.os }}-build-${{ env.cache-name }}
          restore-keys: |
            ${{ runner.os }}-build-${{ env.cache-name }}
            ${{ runner.os }}-build-
            ${{ runner.os }}
      - name: Install system dependencies
        run: |
          rm -rfv /etc/apt/apt.conf.d/docker*
          apt update
          apt install -y --no-install-recommends \
              autoconf automake binutils build-essential ca-certificates \
              clang cmake curl fxt-tools gdb git lcov libfxt-dev libhwloc-dev \
              libopenblas-dev libopenmpi-dev libopenmpi3 libtool-bin \
              lsb-release ninja-build openmpi-bin pkg-config
      - uses: actions/checkout@v4
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - name: Build StarPU
        run: |
          export STARPU_VERSION=starpu-1.4.7
          export STARPU_LABEL=$STARPU_VERSION
          mkdir -p /usr/src
          curl -SL https://gitlab.inria.fr/starpu/starpu/-/archive/$STARPU_LABEL/starpu-$STARPU_LABEL.tar.gz | tar -xzC /usr/src
          ln -s /usr/src/starpu-$STARPU_LABEL /usr/src/starpu
          cd /usr/src/starpu
          ./autogen.sh
          ./configure \
              --disable-build-doc \
              --disable-build-examples \
              --disable-build-tests \
              --disable-fortran \
              --disable-opencl \
              --disable-socl \
              --disable-starpufft \
              --disable-starpupy \
              --enable-blas-lib=none \
              --enable-maxcudadev=8 \
              --enable-maxbuffers=16 \
              --with-fxt
          make -j 4 install
          rm -rf /usr/src/starpu /usr/src/starpu-$STARPU_LABEL
      - name: Upload StarPU libraries (*.so)
        uses: actions/upload-artifact@v4.3.4
        with:
          name: starpu-${{ matrix.python-version }}
          path: /usr/local/lib/lib*.so*
          retention-days: 7
      - name: Build NNTile native libraries
        run: |
          cmake -S . -B build -DCMAKE_BUILD_TYPE=RelWithDebInfo -DUSE_CUDA=OFF
          cmake --build build
      - name: Upload all shared objects (*.so)
        uses: actions/upload-artifact@v4.3.4
        with:
          name: shared-objects-${{ matrix.python-version }}
          path: build/**/*.so
          retention-days: 7

  test-python:
    name: Run CPU-only tests with Python ${{ matrix.python-version }}
    needs: 'build'
    runs-on: 'ubuntu-24.04'
    strategy:
      matrix:
        python-version: ['3.12']
    container:
      image: 'ubuntu:24.04'
    steps:
      - name: Cache system packages
        uses: actions/cache@v4
        id: cache-apt
        env:
          cache-name: cache-apt-packages
        with:
          path: /var/cache/apt
          key: ${{ runner.os }}-build-${{ env.cache-name }}
          restore-keys: |
            ${{ runner.os }}-build-${{ env.cache-name }}
            ${{ runner.os }}-build-
            ${{ runner.os }}
      - name: Install Git in container
        run: |
          rm -rfv /etc/apt/apt.conf.d/docker*
          apt update
          apt install -y --no-install-recommends ca-certificates git
      # NOTE Step order is important for checkout in container: git
      # installation in container precedes repo checkout.
      # NOTE Values of ${GITHUB_WORKSPACE} and ${{ github.workspace }} differ
      # (see https://github.com/actions/checkout/issues/785 for details).
      - uses: actions/checkout@v4
      - name: Pull all PR commits
        if: github.event.pull_request
        run: |
          # Restore `.git` location.
          git config --global --add safe.directory ${GITHUB_WORKSPACE}
          git config --list
          # Un-shallow refs.
          git config remote.origin.fetch "+refs/heads/*:refs/remotes/origin/*"
          # Deepen topic branch; checkout topic branch.
          git fetch origin ${{ github.ref }}:${{ github.head_ref }} \
            --depth=$(( ${{ github.event.pull_request.commits }} + 1 ))
          git checkout ${{ github.event.pull_request.head.ref }}
          # Fetch main for common origin.
          git fetch origin main:main --depth=100
      - name: Install system dependencies
        run: |
          rm -rfv /etc/apt/apt.conf.d/docker*
          apt update
          apt install -y --no-install-recommends \
              autoconf automake binutils build-essential ca-certificates \
              clang cmake curl fxt-tools git lcov libfxt-dev libhwloc-dev \
              libopenblas-dev libopenmpi-dev libopenmpi3 libtool-bin \
              lsb-release ninja-build openmpi-bin pkg-config sqlite3
      - name: Download StarPU libraries (*.so)
        uses: actions/download-artifact@v4
        with:
          name: starpu-${{ matrix.python-version }}
          path: /usr/lib
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - name: Download all shared objects (*.so)
        uses: actions/download-artifact@v4
        with:
          name: shared-objects-${{ matrix.python-version }}
          path: build
      # TODO(@daskol): We should not remove platform tag and rework extension
      # build in general.
      - name: Make in-tree symlink to an extension
        run: |
          ln -rs \
            build/wrappers/python/nntile/nntile_core.so \
            wrappers/python/nntile/nntile_core.so
      # TODO(@daskol): Clean up and prepare `pyproject.toml` for packaging and
      # proper dependency resolution. We must reuse dependency list from
      # `pyproject.toml`.
      - name: Install Python dependencies
        run: |
          python -m pip install -U pip
          # Mandatory dependencies.
          python -m pip install fastapi 'numpy<2' pydantic uvicorn
          # Optional dependencies.
          python -m pip install -i https://download.pytorch.org/whl/cpu \
            torch torchvision
          python -m pip install datasets scipy tokenizers transformers
          # Testing dependencies.
          python -m pip install mypy 'pytest>=8.2' pytest-cov pytest-dirty
      - name: Run dirty tests with PyTest
        if: 'github.event.pull_request'
        run: |
          export PYTHON_TAG=$(
            python -c 'import sys; print(sys.implementation.cache_tag)')
          export PYTHONPATH=$PWD/wrappers/python:$PYTHONPATH
          .github/scripts/run-dirty-tests.sh \
            ${{ github.event.pull_request.head.ref }}
      - name: Run all tests with PyTest
        if: '!github.event.pull_request'
        run: |
          export PYTHON_TAG=$(
            python -c 'import sys; print(sys.implementation.cache_tag)')
          export PYTHONPATH=$PWD/wrappers/python:$PYTHONPATH
          pytest -vv \
            --cov=wrappers/python/nntile \
            --cov-report=html:coverage/html/${PYTHON_TAG} \
            --cov-report=xml:coverage/xml/report.${PYTHON_TAG}.xml \
            --junitxml=pytest/report.${PYTHON_TAG}.xml
      - name: Upload PyTest report for Python ${{ matrix.python-version }}
        uses: actions/upload-artifact@v4.3.4
        with:
          name: pytest-report
          path: |
            coverage
            pytest
      # This step never fails but it is useful to monitor status of type
      # corectness.
      - name: Check typing
        run: mypy wrappers/python/nntile || true
